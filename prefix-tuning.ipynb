{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q peft transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T10:57:08.268935Z","iopub.execute_input":"2024-02-22T10:57:08.269302Z","iopub.status.idle":"2024-02-22T10:57:08.518388Z","shell.execute_reply.started":"2024-02-22T10:57:08.269270Z","shell.execute_reply":"2024-02-22T10:57:08.517478Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e51be7a96cb642a4b63ffa682e8a9ad3"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T10:59:06.275686Z","iopub.execute_input":"2024-02-22T10:59:06.276346Z","iopub.status.idle":"2024-02-22T10:59:06.282313Z","shell.execute_reply.started":"2024-02-22T10:59:06.276314Z","shell.execute_reply":"2024-02-22T10:59:06.281316Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, default_data_collator, get_linear_schedule_with_warmup\nfrom peft import get_peft_config, get_peft_model, get_peft_model_state_dict, PrefixTuningConfig, TaskType\nfrom datasets import load_dataset\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport torch\nimport os\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\ndevice = \"cuda\"\nmodel_name_or_path = \"t5-large\"\ntokenizer_name_or_path = \"t5-large\"\n\ntext_column = \"sentence\"\nlabel_column = \"text_label\"\nmax_length = 128\nlr = 1e-2\nnum_epochs = 5\nbatch_size = 8","metadata":{"execution":{"iopub.status.busy":"2024-02-22T10:58:49.098087Z","iopub.execute_input":"2024-02-22T10:58:49.098793Z","iopub.status.idle":"2024-02-22T10:59:02.434645Z","shell.execute_reply.started":"2024-02-22T10:58:49.098760Z","shell.execute_reply":"2024-02-22T10:59:02.433816Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-02-22 10:58:52.460024: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-22 10:58:52.460164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-22 10:58:52.577218: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset('financial_phrasebank', 'sentences_allagree', revision='main')\ndataset = dataset[\"train\"].train_test_split(test_size=0.1)\ndataset[\"validation\"] = dataset[\"test\"]\ndel dataset[\"test\"]\n\nclasses = dataset[\"train\"].features[\"label\"].names\ndataset = dataset.map(\n    lambda x: {\"text_label\": [classes[label] for label in x[\"label\"]]},\n    batched=True,\n    num_proc=1,\n)\n\ndataset[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-02-22T10:59:12.541018Z","iopub.execute_input":"2024-02-22T10:59:12.541655Z","iopub.status.idle":"2024-02-22T10:59:13.992945Z","shell.execute_reply.started":"2024-02-22T10:59:12.541624Z","shell.execute_reply":"2024-02-22T10:59:13.992069Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/171k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b286917899a94b33be8be033f5e432cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2264 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b06db1946d3347aab8830dd28977df96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2037 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"885eb4d76b97450ba5f32aecc1536074"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/227 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8132a794b494b05a60cafdc155dc1b3"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'sentence': 'Elcoteq SE Stock Exchange Announcement February 4 , 2009 at 10.00 am ( EET ) Elcoteq will publish its financial statements bulletin 2008 on Wednesday , February 11 , at 9.00 am ( EET ) .',\n 'label': 1,\n 'text_label': 'neutral'}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n\n\ndef preprocess_function(examples):\n    inputs = examples[text_column]\n    targets = examples[label_column]\n    model_inputs = tokenizer(inputs, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n    labels = tokenizer(targets, max_length=2, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n    labels = labels[\"input_ids\"]\n    labels[labels == tokenizer.pad_token_id] = -100\n    model_inputs[\"labels\"] = labels\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-02-22T10:59:18.264165Z","iopub.execute_input":"2024-02-22T10:59:18.264538Z","iopub.status.idle":"2024-02-22T10:59:19.181425Z","shell.execute_reply.started":"2024-02-22T10:59:18.264511Z","shell.execute_reply":"2024-02-22T10:59:19.180435Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5b7acebe1be477d87e8b79b8a061ce2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"655e56252d7542c9a193c8c64540f116"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bbaa6283aec4ec8b4fe418caf68d15c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"processed_datasets = dataset.map(\n    preprocess_function,\n    batched=True,\n    num_proc=1,\n    remove_columns=dataset[\"train\"].column_names,\n    load_from_cache_file=False,\n    desc=\"Running tokenizer on dataset\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T10:59:22.697726Z","iopub.execute_input":"2024-02-22T10:59:22.698711Z","iopub.status.idle":"2024-02-22T10:59:23.335046Z","shell.execute_reply.started":"2024-02-22T10:59:22.698675Z","shell.execute_reply":"2024-02-22T10:59:23.334141Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset:   0%|          | 0/2037 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"204b83392fa64baa892f5c0993c94780"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset:   0%|          | 0/227 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d0db3fbae424d0693472b15ba5e5ce7"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = processed_datasets[\"train\"]\neval_dataset = processed_datasets[\"validation\"]\n\ntrain_dataloader = DataLoader(\n    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n)\neval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T10:59:26.563564Z","iopub.execute_input":"2024-02-22T10:59:26.564403Z","iopub.status.idle":"2024-02-22T10:59:26.569662Z","shell.execute_reply.started":"2024-02-22T10:59:26.564373Z","shell.execute_reply":"2024-02-22T10:59:26.568628Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"peft_config = PrefixTuningConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, num_virtual_tokens=20)\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T10:59:30.577910Z","iopub.execute_input":"2024-02-22T10:59:30.578303Z","iopub.status.idle":"2024-02-22T11:00:19.112743Z","shell.execute_reply.started":"2024-02-22T10:59:30.578272Z","shell.execute_reply":"2024-02-22T11:00:19.111859Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"956a0056fdaf4d0495d1ab438d2fadc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1814ff3716c1419d9bf745d709683086"}},"metadata":{}},{"name":"stdout","text":"trainable params: 983,040 || all params: 738,651,136 || trainable%: 0.13308583065659835\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\nlr_scheduler = get_linear_schedule_with_warmup(\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=(len(train_dataloader) * num_epochs),\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:00:43.557492Z","iopub.execute_input":"2024-02-22T11:00:43.558113Z","iopub.status.idle":"2024-02-22T11:00:43.568288Z","shell.execute_reply.started":"2024-02-22T11:00:43.558079Z","shell.execute_reply":"2024-02-22T11:00:43.567206Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:00:45.092742Z","iopub.execute_input":"2024-02-22T11:00:45.093135Z","iopub.status.idle":"2024-02-22T11:00:45.145049Z","shell.execute_reply.started":"2024-02-22T11:00:45.093105Z","shell.execute_reply":"2024-02-22T11:00:45.144100Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"model = model.to(device)\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    for step, batch in enumerate(tqdm(train_dataloader)):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        total_loss += loss.detach().float()\n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n\n    model.eval()\n    eval_loss = 0\n    eval_preds = []\n    for step, batch in enumerate(tqdm(eval_dataloader)):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        with torch.no_grad():\n            outputs = model(**batch)\n        loss = outputs.loss\n        eval_loss += loss.detach().float()\n        eval_preds.extend(\n            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n        )\n\n    eval_epoch_loss = eval_loss / len(eval_dataloader)\n    eval_ppl = torch.exp(eval_epoch_loss)\n    train_epoch_loss = total_loss / len(train_dataloader)\n    train_ppl = torch.exp(train_epoch_loss)\n    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct = 0\ntotal = 0\nfor pred, true in zip(eval_preds, dataset[\"validation\"][\"text_label\"]):\n    if pred.strip() == true.strip():\n        correct += 1\n    total += 1\naccuracy = correct / total * 100\nprint(f\"{accuracy=} % on the evaluation dataset\")\nprint(f\"{eval_preds[:10]=}\")\nprint(f\"{dataset['validation']['text_label'][:10]=}\")\n\"accuracy=97.3568281938326 % on the evaluation dataset\"\n\"eval_preds[:10]=['neutral', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral']\"\n\"dataset['validation']['text_label'][:10]=['neutral', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral']\"","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:07:41.976145Z","iopub.execute_input":"2024-02-22T11:07:41.976530Z","iopub.status.idle":"2024-02-22T11:07:41.987643Z","shell.execute_reply.started":"2024-02-22T11:07:41.976503Z","shell.execute_reply":"2024-02-22T11:07:41.986576Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"accuracy=96.47577092511013 % on the evaluation dataset\neval_preds[:10]=['neutral', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'positive']\ndataset['validation']['text_label'][:10]=['neutral', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'positive']\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"\"dataset['validation']['text_label'][:10]=['neutral', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral']\""},"metadata":{}}]},{"cell_type":"code","source":"peft_model_id = \"likhith231/t5-large_PREFIX_TUNING_SEQ2SEQ\"\nmodel.push_to_hub(\"likhith231/t5-large_PREFIX_TUNING_SEQ2SEQ\", use_auth_token=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:08:03.478039Z","iopub.execute_input":"2024-02-22T11:08:03.478892Z","iopub.status.idle":"2024-02-22T11:08:08.182031Z","shell.execute_reply.started":"2024-02-22T11:08:03.478859Z","shell.execute_reply":"2024-02-22T11:08:08.181046Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:821: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/3.93M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5272cc65e4074a06b625730ab503e5eb"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/likhith231/t5-large_PREFIX_TUNING_SEQ2SEQ/commit/1ad8dc429b1cc93a2939784d1ef6f25c2cd59f2e', commit_message='Upload model', commit_description='', oid='1ad8dc429b1cc93a2939784d1ef6f25c2cd59f2e', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"from peft import PeftModel, PeftConfig\n\npeft_model_id = \"likhith231/t5-large_PREFIX_TUNING_SEQ2SEQ\"\n\nconfig = PeftConfig.from_pretrained(peft_model_id)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path)\nmodel = PeftModel.from_pretrained(model, peft_model_id)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:09:11.317705Z","iopub.execute_input":"2024-02-22T11:09:11.319753Z","iopub.status.idle":"2024-02-22T11:09:14.653923Z","shell.execute_reply.started":"2024-02-22T11:09:11.319702Z","shell.execute_reply":"2024-02-22T11:09:14.653055Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/370 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"250ab455713e4eee830bc6bb4d2ba23e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/3.93M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03834531e6364b5094ed2c5967753638"}},"metadata":{}}]},{"cell_type":"code","source":"inputs = tokenizer(\n    \"The Lithuanian beer market made up 14.41 million liters in January , a rise of 0.8 percent from the year-earlier figure , the Lithuanian Brewers ' Association reporting citing the results from its members .\",\n    return_tensors=\"pt\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:09:22.265443Z","iopub.execute_input":"2024-02-22T11:09:22.266351Z","iopub.status.idle":"2024-02-22T11:09:22.271245Z","shell.execute_reply.started":"2024-02-22T11:09:22.266313Z","shell.execute_reply":"2024-02-22T11:09:22.270223Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model.to(device)\n\nwith torch.no_grad():\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n    outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=10)\n    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:09:28.587309Z","iopub.execute_input":"2024-02-22T11:09:28.587947Z","iopub.status.idle":"2024-02-22T11:09:28.699743Z","shell.execute_reply.started":"2024-02-22T11:09:28.587912Z","shell.execute_reply":"2024-02-22T11:09:28.698830Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"['positive']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}